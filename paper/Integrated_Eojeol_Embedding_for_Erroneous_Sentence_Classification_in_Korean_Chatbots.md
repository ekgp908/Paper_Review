<h3>Integrated Eojeol Embedding for Erroneous Sentence Classification in Korean Chatbots</h3>

 - URL: https://arxiv.org/pdf/2004.05744.pdf

--------------
 - ëª©ì 
   - intentê°€ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ë˜ë©´, ë¶„ë¥˜ëœ intentëŠ” input sentenceì— ëŒ€í•´ entityë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì„ ì‰½ê²Œ í•¨
   - intentë¥¼ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ Integrated Eojeol Embedding(IEE)ë¥¼ ì œì•ˆí•¨

<br>

- ì–´ì ˆ(Eojeol)
   - ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ í•œê¸€ Sequence, í•˜ë‚˜ ì´ìƒì˜ í˜•íƒœì†Œê°€ ë“¤ì–´ìˆìŒ
   - input sentenceëŠ” ì–´ì ˆ list {w_1, w_2,â€¦w_s}ë¥¼ ì–»ê¸° ìœ„í•´ ê³µë°±ìœ¼ë¡œ tokenizeë¨
   - ì–´ì ˆ wë¡œ 4ê°œì˜ subword unit listê°€ ìƒì„±ë¨
     - jamo list
     - character list
     - byte-pair encoding (BPE) subunit list
     - morpheme list
- Integrated Eojeol Embedding(IEE)
  - subword unit merge(SUM) network
    - ì–´ì ˆ ğ‘¤ê°€ ì£¼ì–´ì¡Œì„ ë•Œ IEE vectorë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ network architecture   
![image](https://user-images.githubusercontent.com/54783292/99926994-fa1cef80-2d86-11eb-976b-855a788d68cc.png)   
     1. subword unit listì´ ì…ë ¥ë¨
     2. SUM networkëŠ” ê° list itemì„ embedding vectorë¡œ ë³€í™˜í•˜ì—¬embedding matrixë¥¼ ì–»ìŒ
     3. embedding matrixëŠ” one-dimensional depthwise separable convolutionì— ì ìš©í•¨
     4. Max-poolingê³¼ LayerNormì„ ìˆ˜í–‰í•¨
     5. Integrated Eojeol Embedding vectorëŠ” subword unit-based Eojeol embedding vectorë¥¼ í†µí•´ ê³„ì‚°ë¨
  - IEEë¥¼ êµ¬ì„±í•˜ê¸° ìœ„í•œ 3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜
    - IEE by Concatenation
      - ëª¨ë“  subword unit-based Eojeol embedding vector ë“¤ì„ í•˜ë‚˜ì˜ IEE vectorë¥¼ í˜•ì„±í•˜ë„ë¡ concatenationí•¨
    - IEE by Weighted Sum
      - subword unit-based Eojeol embedding vectorì˜ weighted sumìœ¼ë¡œ ì •ì˜í•¨
    - IEE by Max Pooling
      - subword unit-based Eojeol embedding vectorì˜ jë²ˆì§¸ ìš”ì†Œì˜ maximal valueë¥¼ IEEì˜ jë²ˆì§¸ ìš”ì†Œë¡œ ì„¤ì •í•¨
 - Noise Insertion Methods
   - IEE vectorì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë‘ ê°€ì§€ ë…¸ì´ì¦ˆ ì‚½ì… ë°©ë²•
     - Jamo dropout
       - Training ë‹¨ê³„ì—ì„œ Jamo dropout probabilityë¥¼ í†µí•´ ì „ì²´ Jamo embedding vectorë¥¼ maskingí•¨
       - ë‹¤ë¥¸ ìœ í˜•ì˜ subword unitì— maskëœ jamoê°€ í¬í•¨ëœ ê²½ìš°, í•´ë‹¹ subword unit embedding vectorë„ maskingí•¨
       - input embedding vectorì˜ ì¼ë¶€ ìš”ì†Œë¥¼ dropoutìœ¼ë¡œ maskingí•˜ëŠ” ëŒ€ì‹ , jamo dropoutì€ ì „ì²´ jamo embedding vectorë¥¼ maskingí•¨
       - masked jamoë¥¼ í¬í•¨í•˜ëŠ” ë‹¤ë¥¸ subword unitì„ maskingí•¨ìœ¼ë¡œì¨ subword unit vocabì—ì„œ input subwordë¥¼ ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš° systemì€ jamo embeddingì— ì§‘ì¤‘í•˜ëŠ” ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆìŒ
     - Space-missing sentence generation
       - Trining ë‹¨ê³„ ì „ì— í•œë²ˆë§Œ ì ìš©ë¨
       - msp(missing space probability)ë¥¼ ê°–ëŠ” training corpusë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•˜ê³ , ì„ íƒëœ ë¬¸ì¥ì˜ ëª¨ë“  ê³µë°±ì„ ì œê±°í•œë‹¤
       - ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ì–´ì ˆì„ tokenizeí•˜ê¸° ë•Œë¬¸ì— morpheme embedding-basedë°©ì‹ê³¼ ë¹„êµí•˜ì—¬ eojeol embedding-based ë°©ì‹ì€ ê³µë°±ì´ ì—†ëŠ” ë¬¸ì¥ì— ëŒ€í•´ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒë¨ ê·¸ë˜ì„œ ì´ ë°©ë²• ë„ì…

<br>

 - ë°ì´í„°
   - intent classification corpus
     - 48 intents
     - 127,322ê°œì˜ ë¬¸ë²•ì ìœ¼ë¡œ ì •í™•í•œ í•œêµ­ì–´ ë¬¸ì¥
     - train:validation:test = 8:1:1
   - WF(Well-Formed) corpus
     - test dataset, 12,711ê°œ
   - KM(Korean Misspelling) corpus
     - ì˜¤ë¥˜ê°€ ìˆëŠ” ë¬¸ì¥ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ ìˆ˜ë™ìœ¼ë¡œ ì£¼ì„ ì¶”ê°€
     - 46ê°œì˜ intents (ë¬´ì˜ë¯¸í•œ ë¬¸ì¥ì˜ ì˜ë„ì¸ ood, ì‘ê³¼ ê°™ì€ ì§§ì€ ë‹µë³€ ì˜ë„ë¥¼ ëœ»í•˜ëŠ” common ì œì™¸)
     - 2,070ê°œì˜ ì˜ëª»ëœ ë¬¸ì¥ì„ í¬í•¨ (ê° intentì— ëŒ€í•´ annotatorê°€ ì˜¤ë¥˜ì—†ëŠ” 45ê°œì˜ ë¬¸ì¥ì„ ì‘ì„±í•˜ê³  ë‹¤ìŒ annotatorê°€ ì‘ì„±ëœ ë¬¸ì¥ì— ì˜¤ë¥˜ë¥¼ ì‚½ì…í•¨)
     - testingí•  ë•Œ ì‚¬ìš©
   - SM (Space-missing) test corpus
     - WFì™€ KM corpusë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ë¨
     - í•„ìš”í•œ ê³µë°±ì´ ì—†ëŠ” ë¬¸ì¥ì„ ì„±ëŠ¥ í‰ê°€í•¨(ë‹¨ì–´ ì‚¬ì´ì˜ ê³µë°±ì€ 0.5 í™•ë¥ ë¡œ ëœë¤í•˜ê²Œ ì œê±°ë˜ë©° ì›ë˜ ë¬¸ì¥ì—ì„œ í•˜ë‚˜ ì´ìƒì˜ ê³µë°±ì´ ì œê±°ë¨)
     - 14,781ê°œì˜ ë¬¸ì¥ì„ í¬í•¨
     - testingí•  ë•Œ ì‚¬ìš©

<br>
   
 - ì‹¤í—˜
   - IEE-based Sentence Classification
     - IEEë¥¼ ì‚¬ìš©í•˜ëŠ” sentence classificationì„ ìœ„í•œ network architecture   
![image](https://user-images.githubusercontent.com/54783292/99927012-0a34cf00-2d87-11eb-8542-b77488cfd873.png)   
      1. ì£¼ì–´ì§„ ë¬¸ì¥ sì˜ ì–´ì ˆ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê° ì–´ì ˆì— ëŒ€í•œ IEE matrix ğ¸(ğ‘ )ë¥¼ ì–»ê¸° ìœ„í•´ IEE networkë¡œ ê³„ì‚°í•¨
      2. IEE matrix ğ¸(ğ‘ )ê°€ ê³„ì‚°ë˜ë©´ depthwise separable convolutionì— ì ìš©í•¨
      3. Max-poolingê³¼ LayerNormì„ ìˆ˜í–‰í•¨
      4. ë‘ ê°œì˜ fully connected feed-forward layerì—ì„œ final output score vector ğ‘‚ë¥¼ ì–»ìŒ
 - ì„±ëŠ¥ ì¸¡ì •
   - Sentence accuracy = (correct sentences) / (total sentences)

<br>
   
 - ê²°ê³¼   
   - IEEë¥¼ êµ¬ì„±í•˜ëŠ” 3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ì‹¤í—˜ ê²°ê³¼   
![image](https://user-images.githubusercontent.com/54783292/99927033-2f294200-2d87-11eb-841f-fa0b7ed10544.png)   
     - IEEc(IEE by Concatenation), IEEm(IEE by Max-pooling), IEEw(IEE by Weighted Sum)
     - [m]: morpheme, [b]: BPE unit, [j]: Jamo, [c]: Character
     - ë‘ ê°€ì§€ ë…¸ì´ì¦ˆ ì‚½ì… ë°©ë²•ì„ ëª¨ë‘ ì‚¬ìš©í–ˆì„ ë•Œ, ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ë³´ë‹¤ í¬ê²Œ í–¥ìƒë¨
   - IMEì™€ IBEì— ëŒ€í•œ ë¹„êµ ì‹¤í—˜ ê²°ê³¼   
![image](https://user-images.githubusercontent.com/54783292/99927047-3bad9a80-2d87-11eb-939c-b5727f8be5ca.png)   
     - IME(integrated morpheme embedding), IBE(integrated BPE embedding)
       - IEE-based Sentence Classificationê³¼ì •ì—ì„œ Eojeol embedding vectorë¥¼ ê³µê¸‰í• ë•Œ, morpheme embedding VECTORì™€ BPE unit embedding vectorë¥¼ ê³µê¸‰í•œë‹¤ëŠ” ì ì„ ë¹¼ë©´ IEEì™€ ë™ì¼
     - KM corpusì˜ ê²½ìš° ì–´ì ˆ ê¸°ë°˜ embeddinì´ í˜•íƒœì†Œì™€ BPE ê¸°ë°˜ì˜ ë°©ì‹ì— ë¹„í•´ 3% ë” ë†’ìŒ
   - ë‹¤ì–‘í•œ subword unitìœ¼ë¡œ êµ¬ì„±ëœ IEEcì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼   
![image](https://user-images.githubusercontent.com/54783292/99927070-4831f300-2d87-11eb-9638-97efc8e12bdb.png)   
     - Jamo subwordë¥¼ ì ìš©í•˜ë©´ KM corpusì—ì„  ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë¨
     - Jamo subword unitì€ pre-trained embeddingì´ ì—†ê¸° ë•Œë¬¸ì— WF Corpusì—ì„œëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ì €í•˜
