<h3>ConveRT: Efficient and Accurate Conversational Representations from Transformers</h3>

 - URL: https://arxiv.org/pdf/1911.03688.pdf

--------------
 - ëª©ì 
   - íš¨ê³¼ì ì´ê³  ì €ë ´í•˜ê³  í•™ìŠµì´ ë¹ ë¥¸ ëª¨ë¸ ì œì•ˆ

<br>
  
 - ëª¨ë¸
   - Single-Context Model    
![image](https://user-images.githubusercontent.com/54783292/99364190-07565c00-28f9-11eb-992b-a90cae75d18c.png)
     - ë‘ ê°œì˜ ë‹¤ë¥¸ feed-forward network (FFN) layer
       - feed-forward 1ì€ standard FFN layer ë¡œ êµ¬ì„±
       - Feed-forworward 2 ëŠ” 3ê°œì˜ fully-connected nonlinear feed-forward layerì™€ ê·¸ ë’¤ì— ìµœì¢… linear layer ë¡œ êµ¬ì„±
     - Self-attention blocksì „ì— subword embedding inputsì— positional enconding ì¡´ì¬
     - 6ê°œì˜ layerëŠ” long sequencesì™€ distant dependenciesë¥¼ ì¼ë°˜í™”í•˜ëŠ”ë° ë„ì›€ì´ ë¨
     - ë‹¤ë¥¸ ë„¤íŠ¸ì›Œí¬ ê³„ì¸µì—ì„œ í•™ìŠµëœ ì¸ì½”ë”©ì„ intent detection ì´ë‚˜ value extractionê³¼ ê°™ì€ ë‹¤ë¥¸ ì‘ì—…ìœ¼ë¡œ ë³´ë‚¼ ìˆ˜ ìˆìŒ
     - ì‚¬ìš©ë˜ëŠ” ëª¨ë“  activation functionì€ fast GeLU approximation 
   - Multi-Context Model    
![image](https://user-images.githubusercontent.com/54783292/99364227-11785a80-28f9-11eb-859f-a5fd87625472.png)
     - ì¦‰ê°ì ì¸ contextì™€ ì´ì „ ëŒ€í™” ë‚´ì—­ì„ ê²°í•©í•œ multi-context dual-encoder model
       - ì¦‰ê°ì ì¸ contextì™€ ê·¸ì— ë”°ë¥´ëŠ” responseì˜ ìƒí˜¸ì‘ìš©
       - ëŒ€í™” ë‚´ì—­ì—ì„œ ìµœëŒ€ 10ê°œì˜ ì´ì „ contextì™€ responseì˜ ìƒí˜¸ì‘ìš©
       - ì „ì²´ contextì™€ responseì˜ ìƒí˜¸ì‘ìš©
     - Transformer layerëŠ” singe context encoder ëª¨ë¸ì„ ì°¸ì¡°í•¨
     - feed-forward 2 blocksì€ singe context encoder ì™€ ë™ì¼

<br>
    
 - ë°ì´í„°  
   - Response Selection
     - Reddit Data: 727M ê°œì˜ input-response ìŒ, 654M train ë‚˜ë¨¸ì§€ test
     - AMAZONQA: Amazon ì œí’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ì§ˆë¬¸-ì‘ë‹µ ìŒìœ¼ë¡œ ëœ ì „ì ìƒê±°ë˜ ë°ì´í„°ì…‹
     - DSTC7- UBUNTU: 1M+ ê°œì˜ Ubuntu v2 corpus, 10K train/10K validation/5K test
   - Intent Classification   
![image](https://user-images.githubusercontent.com/54783292/99364249-1806d200-28f9-11eb-9e1b-5902bb9dc931.png)
     - train : validation : test = 8 : 1 : 1

<br>

- ì‹¤í—˜
  - Response Selection
    - ëŒ€í™” ë‚´ì—­ì´ ì£¼ì–´ì§€ë©´ ê°€ì¥ ì ì ˆí•œ ì‘ë‹µ ì„ íƒí•˜ê¸°
    - ë¬¸ë§¥ê³¼ ì‘ë‹µ ì»¬ë ‰ì…˜ì„ ì¸ì½”ë”©í•œ í›„, ê° í›„ë³´ ì‘ë‹µì˜ ì¸ì½”ë”©ì— ëŒ€í•´ ì¿¼ë¦¬ í‘œí˜„ì„ ì¼ì¹˜ì‹œì¼œ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ì‘ë‹µì„ ê²€ìƒ‰í•¨
    - labelì´ ì—†ëŠ” ëŒ€í™” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•œ í›„, ì ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ë ˆì´ì–´ë¥¼ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì„ fine-tuningí•¨
    - ë¹„êµ ëª¨ë¸: USE-LARGE, BERT-LARGE, USE-QA, POLYAI-DUAL
  - Intent Classification
    - encoding ğ‘Ÿ_ğ‘¥ ë¥¼ inputìœ¼ë¡œ ì‚¬ìš©
    - encoderë¥¼ ê³ ì •í•˜ê³ , sentence encodingìœ„ì— classifier layerë¥¼ ë‘ì–´ í•™ìŠµí•¨
    - ë¹„êµ ëª¨ë¸: USE-LARGE, BERT-LARGE
<br>

- ì„±ëŠ¥ ì¸¡ì •
  - Response Selection: Recall@k

<br>
   
 - ê²°ê³¼
   - ê¸°ì¡´ encoderì— ë¹„í•´ cost ì ˆê°, model size ì‘ìŒ, training time ë¹ ë¦„
![image](https://user-images.githubusercontent.com/54783292/99364276-205f0d00-28f9-11eb-82f0-9a5b6d9d9267.png)
   - Response Selection (Reddit,AmazonQA / DSTC7-UBUNTU)   
![image](https://user-images.githubusercontent.com/54783292/99364312-294fde80-28f9-11eb-9967-88ee6ac69f2c.png)   
![image](https://user-images.githubusercontent.com/54783292/99364361-38369100-28f9-11eb-8457-a8f2b2dd9031.png)
  - Intent Classification   
![image](https://user-images.githubusercontent.com/54783292/99364382-3d93db80-28f9-11eb-8f2c-1ff171be0476.png)
